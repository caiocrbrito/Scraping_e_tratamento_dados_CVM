{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehDMfxr1lJO3"
   },
   "outputs": [],
   "source": [
    "# Scrip para download de arquivos da CVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22533,
     "status": "ok",
     "timestamp": 1686679146516,
     "user": {
      "displayName": "ESTAGIARIO2 CGR",
      "userId": "10244625530664156514"
     },
     "user_tz": 180
    },
    "id": "53Ynobx4F4Pj",
    "outputId": "4e9f978f-0f3f-4858-d52d-d82cbcae3496"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (1.26.15)\n",
      "mkdir: cannot create directory ‘arquivos’: File exists\n"
     ]
    }
   ],
   "source": [
    "#  # Bibliotecas a serem instaladas\n",
    "# !pip install -q bs4\n",
    "# !pip install -q wget\n",
    "# !pip install -q requests\n",
    "\n",
    "#  # Instalar caso a versao do python nao seja compativel com urllib\n",
    "#  !pip install urllib3\n",
    "\n",
    "#  # Diretorio criado para armazenar os dados\n",
    "# !mkdir arquivos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1686679146517,
     "user": {
      "displayName": "ESTAGIARIO2 CGR",
      "userId": "10244625530664156514"
     },
     "user_tz": 180
    },
    "id": "Xbi5yVuGZr4f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os, shutil\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "# import wget\n",
    "\n",
    "class Cvm():\n",
    "\n",
    "    def __init__(self, url):\n",
    "\n",
    "        self.url = url\n",
    "        self.html = ''\n",
    "        self.soup = ''\n",
    "        self.pages = []\n",
    "        self.files = []\n",
    "        self.file_ = []\n",
    "\n",
    "    def get_parser(self):\n",
    "\n",
    "        self.html = requests.get(self.url)\n",
    "\n",
    "        self.soup = BeautifulSoup(self.html.text, 'html.parser')\n",
    "\n",
    "    def get_status(self):\n",
    "\n",
    "        print(self.html.status_code)\n",
    "\n",
    "    def get_files(self, lista):\n",
    "\n",
    "        ''' Funcao que percorre todas as paginas selecionadas e salva os links\n",
    "        para a funcao de download '''\n",
    "        # print('lista de logs:')\n",
    "        for file in lista:\n",
    "\n",
    "            self.html = requests.get(self.url + file)\n",
    "\n",
    "            self.soup = BeautifulSoup(self.html.text, 'html.parser')\n",
    "\n",
    "            # Buscando a ultima data de atualizacao do arquivo\n",
    "            date = self.soup.find('table',\n",
    "                             {'class': 'table table-striped table-bordered table-condensed'})\\\n",
    "                             .find('span',\n",
    "                                   {'class': 'automatic-local-datetime'})\\\n",
    "                                   .getText()\\\n",
    "                                   .strip()\n",
    "\n",
    "            last_update = f'{self.url + file} - {date}'\n",
    "            # print(last_update)\n",
    "\n",
    "            ''' Bloco que tenta ler o arquivo de log ou cria um novo, caso nao encontre\n",
    "                Se existir um arquivo com mesmo nome e a mesma data e hora de atualizacao\n",
    "                no arquivo de log, o arquivo nao sera adicionado a lista para download '''\n",
    "            try:\n",
    "                with open('ultima_atualizacao.txt', 'r') as f:\n",
    "                    content = f.read()\n",
    "                    if last_update in content:\n",
    "                        pass\n",
    "                    else:\n",
    "                        for link in self.soup.find('section', {'id': 'dataset-resources'}).find_all('a'):\n",
    "                            self.file_.append(link.get('href').split('\\n'))\n",
    "                        with open('ultima_atualizacao.txt', 'w') as f:\n",
    "                            f.write(content)\n",
    "                            f.write(last_update)\n",
    "                            f.write('\\n')\n",
    "            except:\n",
    "                with open('ultima_atualizacao.txt', 'w') as f:\n",
    "                    f.write(last_update)\n",
    "                    f.write('\\n')\n",
    "                    for link in self.soup.find('section', {'id': 'dataset-resources'}).find_all('a'):\n",
    "                        self.file_.append(link.get('href').split('\\n'))\n",
    "\n",
    "\n",
    "    def download(self, output = './', date_ignore=None, ano='2022'):\n",
    "        \n",
    "        # Criando pasta temporaria\n",
    "        os.mkdir('../dados/temp')\n",
    "        \n",
    "        ''' Funcao que faz o download de todos os arquivos mapeados no diretorio\n",
    "        selecionado '''\n",
    "        print('Arquivos baixados:')\n",
    "        for i in self.file_:\n",
    "            if ('http' in i[0]) & ('2018' not in i[0]) & ('2019' not in i[0]) \\\n",
    "                & ('/META/' not in i[0]) & (i[0][i[0].rfind(ano):i[0].rfind(ano)+6] not in date_ignore):\n",
    "\n",
    "                ''' Olha no diretorio de armazenamento dos arquivos,\n",
    "                    caso haja uma atualizacao e o arquivo esteja na lista,\n",
    "                    sera removido o arquivo anterior e salvo a nova versao '''\n",
    "                file_name = i[0]\n",
    "                if file_name.split('/')[-1] in os.listdir(output):\n",
    "                    # print(file_name)\n",
    "                    try:\n",
    "                        os.remove(f'{output}/{file_name.split(\"/\")[-1]}')\n",
    "                        sleep(2)\n",
    "                        # wget.download(file_name, out = output)\n",
    "                        urllib.request.urlretrieve(file_name, output + file_name.split('/')[-1])\n",
    "                        print(file_name)\n",
    "                    except:\n",
    "                        os.remove(f'{output}{file_name.split(\"/\")[-1]}')\n",
    "                        sleep(2)\n",
    "                        # wget.download(file_name, out = output)\n",
    "                        urllib.request.urlretrieve(file_name, output + file_name.split('/')[-1])\n",
    "                        print(file_name)\n",
    "                else:\n",
    "                    # wget.download(file_name, out = output)\n",
    "                    urllib.request.urlretrieve(file_name, output + file_name.split('/')[-1])\n",
    "                    print(file_name)\n",
    "\n",
    "\n",
    "def concat_fidc(nome='fidc.csv', entrada='/', saida='/'):\n",
    "\n",
    "    ''' Funcao para agrupar os arquivos fidc e selecionar as colunas de interesse '''\n",
    "\n",
    "    lista_arquivos = []\n",
    "    for arquivo in glob.glob(f'{entrada}/inf_mensal_fidc_*.zip'):\n",
    "        with ZipFile(arquivo, 'r') as obj:\n",
    "            obj.extractall(path='../dados/temp/')\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for arquivo in glob.glob('../dados/temp/*fidc_tab_I_*.csv'):\n",
    "        # lista_arquivos.append(arquivo)\n",
    "        df_temp = pd.read_csv(arquivo,\n",
    "                                sep=';',\n",
    "                                dtype=str,\n",
    "                                encoding = 'ISO-8859-1')\n",
    "        columns = []\n",
    "        for i in range(len(df_temp.columns)):\n",
    "            if (df_temp.columns[i] in ['CNPJ_FUNDO', 'DENOM_SOCIAL', 'DT_COMPTC']) | ('CNPJ_CEDENTE' in df_temp.columns[i]):\n",
    "                columns.append(df_temp.columns[i])\n",
    "        df_temp = df_temp[columns]\n",
    "\n",
    "        df = df.append(df_temp)\n",
    "\n",
    "    if not os.path.exists(saida):\n",
    "        os.makedirs(saida)\n",
    "\n",
    "    df.to_csv(saida + '/' + nome, sep=';', index=False, encoding='utf-8')\n",
    "\n",
    "    shutil.rmtree(entrada + '/temp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35229,
     "status": "ok",
     "timestamp": 1686677552186,
     "user": {
      "displayName": "ESTAGIARIO2 CGR",
      "userId": "10244625530664156514"
     },
     "user_tz": 180
    },
    "id": "xA6jpsz9Wvlt",
    "outputId": "fbd797f3-e0df-4123-85fd-2e0a99acde6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos baixados:\n",
      "https://dados.cvm.gov.br/dados/FI/CAD/DADOS/cad_fi.csv\n",
      "https://dados.cvm.gov.br/dados/FI/CAD/DADOS/cad_fi_hist.zip\n",
      "https://dados.cvm.gov.br/dados/CIA_ABERTA/CAD/DADOS/cad_cia_aberta.csv\n",
      "https://dados.cvm.gov.br/dados/FII/DOC/INF_TRIMESTRAL/DADOS/inf_trimestral_fii_2020.zip\n",
      "https://dados.cvm.gov.br/dados/FII/DOC/INF_TRIMESTRAL/DADOS/inf_trimestral_fii_2021.zip\n",
      "https://dados.cvm.gov.br/dados/FII/DOC/INF_TRIMESTRAL/DADOS/inf_trimestral_fii_2022.zip\n",
      "https://dados.cvm.gov.br/dados/FII/DOC/INF_TRIMESTRAL/DADOS/inf_trimestral_fii_2023.zip\n",
      "https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/itr_cia_aberta_2020.zip\n",
      "https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/itr_cia_aberta_2021.zip\n",
      "https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/itr_cia_aberta_2022.zip\n",
      "https://dados.cvm.gov.br/dados/CIA_ABERTA/DOC/ITR/DADOS/itr_cia_aberta_2023.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202210.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202211.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202212.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202301.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202302.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202303.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202304.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202305.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202306.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202307.zip\n",
      "https://dados.cvm.gov.br/dados/FIDC/DOC/INF_MENSAL/DADOS/inf_mensal_fidc_202308.zip\n"
     ]
    }
   ],
   "source": [
    "# Caminho da pagina principal\n",
    "url = 'https://dados.cvm.gov.br/dataset'\n",
    "\n",
    "# Caminho das extensoes\n",
    "endpoint = ['/fi-cad',\n",
    "         '/cia_aberta-cad',\n",
    "         '/fii-doc-inf_trimestral',\n",
    "         '/cia_aberta-doc-itr',\n",
    "         '/fidc-doc-inf_mensal']\n",
    "\n",
    "# Datas a serem ignoradas\n",
    "ignore = ['202201', '202202', '202203', '202204', '202205', '202206',\n",
    "          '202207', '202208', '202209']\n",
    "\n",
    "# Chamada das funcoes de download\n",
    "caminho_download = '../dados'\n",
    "caminho_concat_fidc = '../dados/fidc'\n",
    "\n",
    "cvm = Cvm(url)\n",
    "cvm.get_parser()\n",
    "cvm.get_files(endpoint)\n",
    "cvm.download(caminho_download, date_ignore=ignore)\n",
    "\n",
    "# Chamada da funcao de concatenacao dos arquivos fidc\n",
    "concat_fidc(entrada=caminho_download, saida=caminho_concat_fidc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat_fidc.ipynb  cvm_ws.ipynb  ultima_atualizacao.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Agora foi criado um novo arquivo contendo informacoes dos arquivos baixados\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos baixados:\n"
     ]
    }
   ],
   "source": [
    "# Caminho da pagina principal\n",
    "url = 'https://dados.cvm.gov.br/dataset'\n",
    "\n",
    "# Caminho das extensoes\n",
    "endpoint = ['/fi-cad',\n",
    "         '/cia_aberta-cad',\n",
    "         '/fii-doc-inf_trimestral',\n",
    "         '/cia_aberta-doc-itr',\n",
    "         '/fidc-doc-inf_mensal']\n",
    "\n",
    "# Datas a serem ignoradas\n",
    "ignore = ['202201', '202202', '202203', '202204', '202205', '202206',\n",
    "          '202207', '202208', '202209']\n",
    "\n",
    "# Chamada das funcoes de download\n",
    "caminho_download = '../dados'\n",
    "caminho_concat_fidc = '../dados/fidc'\n",
    "\n",
    "cvm = Cvm(url)\n",
    "cvm.get_parser()\n",
    "cvm.get_files(endpoint)\n",
    "cvm.download(caminho_download, date_ignore=ignore)\n",
    "\n",
    "# Chamada da funcao de concatenacao dos arquivos fidc\n",
    "concat_fidc(entrada=caminho_download, saida=caminho_concat_fidc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
